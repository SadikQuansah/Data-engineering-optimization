{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4ts7DBmTDY-"
   },
   "source": [
    "# Optimization\n",
    "\n",
    "## Exercise 1.1: Bisection \n",
    "\n",
    "One of the most common algorithms for numerical root-finding is *bisection*.\n",
    "\n",
    "To understand the idea, recall the well-known game where:\n",
    "\n",
    "- Player A thinks of a secret number between 1 and 100  \n",
    "- Player B asks if itâ€™s less than 50  \n",
    "  \n",
    "  - If yes, B asks if itâ€™s less than 25  \n",
    "  - If no, B asks if itâ€™s less than 75  \n",
    "  \n",
    "And so on.\n",
    "\n",
    "This is bisection, a relative of [binary search](https://en.wikipedia.org/wiki/Binary_search_algorithm). It works for all sufficiently well behaved increasing continuous functions with $ f(a) < 0 < f(b) $. \n",
    "\n",
    "Write an implementation of the bisection algorith, `bisect(f, lower=0, upper=1, tol=10e-5)` which, given a function `f`, a lower bound `lower` and an upper bound `upper` finds the point `x` where `f(x) = 0`. The parameter `tol` is a numerical tolerance, you should stop once your step size is smaller than `tol`.\n",
    "\n",
    "\n",
    "Use it to minimize the function:\n",
    "\n",
    "$$\n",
    "f(x) = \\sin(4 (x - 1/4)) + x + x^{20} - 1 \\tag{2}\n",
    "$$\n",
    "\n",
    "in python: `lambda x: np.sin(4 * (x - 1/4)) + x + x**20 - 1`\n",
    "\n",
    "The value where f(x) = 0 should be around `0.408`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 473,
     "status": "ok",
     "timestamp": 1612026051239,
     "user": {
      "displayName": "jasleen Kaur",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitSy-VVABi645nqScpV23oW5NBCAa7lTQqdIKl=s64",
      "userId": "12125715966921775581"
     },
     "user_tz": 300
    },
    "id": "APCsVC6aTDZU",
    "outputId": "4219b00e-a8fc-4035-e59c-5d646790cd87"
   },
   "outputs": [],
   "source": [
    "# exercise 1.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmqA0a14TDZb"
   },
   "source": [
    "## Exercise 1.2: (BONUS-STRETCH ðŸ‘¹)  Recursive Bisect\n",
    "\n",
    "Write a recursive version of the bisection algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbE19gJUTDZc",
    "outputId": "5a4ad2be-222b-4d44-bfd7-ada5bc7ca04d"
   },
   "outputs": [],
   "source": [
    "# exercise 1.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toeE5NtkTDZe"
   },
   "source": [
    "## Exercise 2.1: Movies Regression\n",
    "\n",
    "Write the best linear regression model you can on the [Movies Dataset](https://www.kaggle.com/rounakbanik/the-movies-dataset?select=ratings.csv) to predict the profitability of a movie (revenue - budget). Maintain the interpretability of the model.\n",
    "\n",
    "Few notes:\n",
    "\n",
    "1. Clean your data! Movies where the budget or revenue are invalid should be thrown out\n",
    "2. Be creative with feature engineering. You can include processing to one-hot encode the type of movie, etc.\n",
    "3. The model should be useful for someone **who is thinking about making a movie**. So features like the popularity can't be used. You could, however, use the ratings to figure out if making \"good\" or \"oscar bait\" movies is a profitable strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPi9xcx3mywk"
   },
   "outputs": [],
   "source": [
    "# exercise 2.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3qcfNu9TDZh"
   },
   "source": [
    "## Exercise 2.2: Movies Manual Regression\n",
    "\n",
    "Use your `X` and `y` matrix from 2.1 to calculate the linear regression yourself using the normal equation $(X^T X)^{-1}X^Ty$.\n",
    "\n",
    "Verify that the coefficients are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PH6MaM4cTDZi"
   },
   "outputs": [],
   "source": [
    "# exercise 2.2\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Workshop_ Maximum likelihood.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
